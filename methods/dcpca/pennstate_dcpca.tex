\documentclass[12pt]{article}
\renewcommand\abstractname{\textbf{ABSTRACT}}
%----------Packages----------
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsrefs}
\usepackage{dsfont}
\usepackage{mathrsfs}
\usepackage{stmaryrd}
\usepackage[all]{xy}
\usepackage[mathcal]{eucal}
\usepackage{verbatim}  %%includes comment environment
\usepackage{fullpage}  %%smaller margins
\usepackage{times}
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{float}
%\usepackage{cite}
\usepackage{setspace}
%----------Commands----------
%%penalizes orphans
\clubpenalty=9999
\widowpenalty=9999
\providecommand{\abs}[1]{\lvert #1 \rvert}
\providecommand{\norm}[1]{\lVert #1 \rVert}
\usepackage{ amssymb }
\providecommand{\x}{\times}
\usepackage{sectsty}
\usepackage{lipsum}
\usepackage{titlesec}
\titleformat*{\section}{\normalsize\bfseries\scshape}
\titleformat*{\subsection}{\normalsize}
\titleformat*{\subsubsection}{\normalsize\bfseries\filcenter}
\titleformat*{\paragraph}{\normalsize\bfseries\filcenter}
\titleformat*{\subparagraph}{\normalsize\bfseries\filcenter}
\usepackage{indentfirst}
\providecommand{\ar}{\rightarrow}
\providecommand{\arr}{\longrightarrow}
%\hyphenpenalty  10000
%\exhyphenpenalty 10000
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage[top=1in,bottom=1in,right=1in,left=1in,headheight=200pt]{geometry}
\pagestyle{fancy}
\lhead{Penn State}
\chead{}
\rhead{Doppler-constrained Principal Components Analysis (DCPCA)}
\cfoot{\thepage}
\titlespacing*{\section}{0pt}{0.75\baselineskip}{0.1\baselineskip}
\usepackage[labelfont=sc]{caption}
\captionsetup{labelfont=bf}
%\doublespacing

\begin{document}
\section{Description of the Method}
\subsection{Please provide a short (1-2 paragraph) summary of the general idea of the method.  What does it do and how?  If the method has been previously published, please provide a link to that work in addition to answering this and the following questions.}

We applied a variant of the Doppler-constrain Principal Components Analysis (DCPCA) method that is described in Jones et al. (2020; https://arxiv.org/abs/1711.01318).
Both Jones and Gilbertson et al. (2020; https://arxiv.org/abs/2009.01085, accepted to AJ) have applied DCPCA to SOAP simulations.
Since the barycentric-frame wavelengths vary from exposure to the next, we replace the implementation in Jones et al. (2020) with a version that first computes the RVs via traditional cross-correlation function (CCF) methods, and interpolates the spectra onto a common wavelength grid while removing the best-fit RV using a Matern 5/2 Gaussian Process (GP).
From there, we apply a Principal Components Analysis (PCA) analysis to the flux spectra and use the scores for the first principal component as our activity indicator.
To compute a ``clean RV'', we subtract the RV predicted by a linear regression on the scores versus CCF velocities.
One other difference from the Jones et al. (2020) and Gilbertson et al. (2020) use of DCPCA is that rather than using the entire spectrum, we use chunks of spectrum around the same lines as used for the CCF calculation.
This allowed us to avoid regions potentially contaminated by telluric variability.
It also allows more direct comparison of results accross methods.


\subsection{What is the method sensitive to? (e.g. asymmetric line shapes, certain periodicities, etc.)}
The method is sensitive to line shape changes, including changes in the differential changes in line depths, widths and assymetries between lines.

\subsection{Are there any known pros/cons of the method?  For instance, is there something in particular that sets this analysis apart from previous methods?}
This method has the potential to exploit information about changes in shapes lines that are
Given the small number of observations and large temporal gaps for the HD 1010501 dataset, we did not apply the multivariate Gaussian Process models recommended by Jones et al. (2020) or Gilbertson et al. (2020).
Therefore, our method is sensitive only to changes in the wavelength domain and does not use any temporal information.
We hope that future datasets will include a sufficient number and spacing of observations to allow us to exploit the temporal information.

\subsection{What does the method output and how is this used to mitigate contributions from photospheric velocities?}
The method provides scores for each principal component.  Ideally, these would be used with a multivariate GP to model stellar activity-induced RVs.  For the HD 101501 dataset, we use only linear regression.
In principle, one can use the basis vectors associated with each principal component to understand what features in the spectra are contributing to each score.

\subsection{Other comments?}

NA

\section{Data Requirements}
\subsection{What is the ideal data set for this method?  In considering future instrument design and observation planning, please comment specifically on properties such as the desired precision of the data, resolution, cadence of observations, total number of observations, time coverage of the complete data set, etc.}

The high spectral resolution and SNR of EXPRES are well suited to this method.  In the future, a larger number of observations and more closely spaced observations would allow us to combine the DCPCA method with a multivariate GP to exploit temporal information, as well as the spectroscopic information.

The ideal dataset would have broad wavelength coverage.
We lost a significant portion of the spectrum available due to only using regions with LFC wavelength calibration.
We may explore relaxing this constraint in the future.

\subsection{Are there any absolute requirements of the data that must be satisfied in order for this method to work?  Rough estimates welcome.}


\subsection{Other comments?}

NA

\section{Applying the Method}
\subsection{What adjustments were required to implement this method on \texttt{EXPRES} data?  Were there any unexpected challenges?}

The second observation had substantially lower signal-to-noise than other spectra.
Therefore, we omitted this spectra when computing the basis vectors.

As noted above, we modified the original DCPCA method to deal with variation int the observed barycentric wavelenegths and location of telluric features.

\subsection{How robust is the method to different input parameters, i.e. does running the method require a lot of tuning to be implemented optimally?}

The algorithm appears to be quite robust, assuming we fix which wavelength ranges are being used.
We include results based on three different line lists, so as to illustrate the sensitivity of the method to different choices of linelists.

\subsection{What metric does the method (or parameter tuner) use internally to decide if the method is performing better or worse?  (e.g. nightly RMS, specific likelihood function, etc.)}

Once the  wavelength ranges are being used are fixed, the only tuning is the number of principal components to use.
We simply chose to use a simple principal component given the small size of the dataset.
If there were a much larger number of observations, then we could divide the data into training and test subsets to choose the number of principal components via cross validation.

\subsection{Other comments?}

NA

\section{Reflection on the Results}
\subsection{Did the method perform as expected?  If not, are there adjustments that could be made to the data or observing schedule to enhance the result?}

It's hard to know how the method performed, since we don't know the true velocity of the star and there aren't as many observations as would be needed to perform cross validation.
Having observations more closely spaced (e.g., one observation each night for several rotation periods) would be expected to improve the performance, as we could then use the time-domain information.

\subsection{Was the method able to run on all exposures?  If not, is there a known reason why it failed for some exposures?}

Yes.
However, the results for the second exposure are somewhat questionable.
It's not clear if this is due to the data (e.g., non-linear detector response) or analysis (e.g., normalization).

\subsection{If the method is GP based, please provide the kernel used and the best-fit hyper parameters with errors.  Otherwise, just write ``Not Applicable.''}
Not Applicable.

\subsection{Other comments?}


\section{General Comments}

We provide results based on three different line lists.
Results in dcpca0 were based on using the ESPRESSO G8 line list to compute CCFs and identify wavelength regions for applying DCPCA.
The other two line lists used were custom built for this star based on the EXPRES data and VALD, as described in the accompanying methods document on CCFs.
Each line list was filtered to only use lines that were available, on the same order, telluric-free, and LFC-calibrated for all observations.
After filtering, the linelist for dcpca1 (dcpca2) contained 332 (389) lines.

\end{document}
